{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6808715",
   "metadata": {},
   "source": [
    "# Sistema de Detección y Seguimiento de Tráfico con YOLOv8\n",
    "\n",
    "## Proyecto: Control de Aforo y Flujo Vehicular\n",
    "\n",
    "**Autores:** Miranda Alison, Morán David, Vivanco Gabriel  \n",
    "**Fecha:** Febrero 2026  \n",
    "**Versión:** 2.0.0\n",
    "\n",
    "---\n",
    "\n",
    "## Tabla de Contenidos\n",
    "\n",
    "1. [Introducción al Proyecto](#introduccion)\n",
    "2. [Tecnologías Utilizadas](#tecnologias)\n",
    "3. [Dataset COCO](#coco)\n",
    "4. [Modelo YOLOv8](#yolo)\n",
    "5. [Arquitectura del Sistema](#arquitectura)\n",
    "6. [Archivos del Proyecto](#archivos)\n",
    "7. [Instalación y Configuración](#instalacion)\n",
    "8. [Ejemplos de Uso](#ejemplos)\n",
    "9. [Resultados](#resultados)\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Qué hace este proyecto?\n",
    "\n",
    "Este sistema utiliza **inteligencia artificial** para detectar y rastrear personas y vehículos en imágenes, permitiendo:\n",
    "- **Control de Aforo:** Contar personas y verificar si se excede la capacidad máxima\n",
    "- **Flujo Vehicular:** Analizar tráfico y determinar niveles de congestión\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24375beb",
   "metadata": {},
   "source": [
    "# 1. Introducción al Proyecto\n",
    "\n",
    "## Objetivo Principal\n",
    "\n",
    "Desarrollar un sistema inteligente de análisis de tráfico que permita:\n",
    "\n",
    "- **Detectar automáticamente** personas y vehículos en imágenes\n",
    "- **Rastrear objetos** con IDs únicos y trayectorias\n",
    "- **Analizar escenarios reales** como control de aforo y flujo vehicular\n",
    "- **Generar alertas visuales** mediante indicadores de color (verde/amarillo/rojo)\n",
    "\n",
    "## Casos de Uso\n",
    "\n",
    "### Control de Aforo\n",
    "Ideal para tiendas, restaurantes, eventos:\n",
    "- Cuenta personas en una ubicación\n",
    "- Alerta cuando se excede capacidad máxima\n",
    "- Muestra indicador verde (apto) o rojo (excedido)\n",
    "\n",
    "### Flujo Vehicular\n",
    "Para análisis de tráfico urbano:\n",
    "- Detecta autos, motos, buses y camiones\n",
    "- Clasifica el tráfico: fluido, moderado o congestionado\n",
    "- Proporciona estadísticas por tipo de vehículo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe8284",
   "metadata": {},
   "source": [
    "# 2. Tecnologías Utilizadas\n",
    "\n",
    "## Stack Tecnológico\n",
    "\n",
    "| Tecnología | Versión | Propósito |\n",
    "|------------|---------|-----------|\n",
    "| **Python** | 3.13+ | Lenguaje de programación principal |\n",
    "| **YOLOv8** | ultralytics 8.4.12 | Modelo de detección de objetos |\n",
    "| **OpenCV** | 4.13.0 | Procesamiento de imágenes y visualización |\n",
    "| **NumPy** | 2.4.2 | Operaciones numéricas y arrays |\n",
    "| **Pillow** | 12.1.0 | Manejo de imágenes |\n",
    "| **Requests** | - | Descarga de imágenes desde URLs |\n",
    "\n",
    "## ¿Por qué estas tecnologías?\n",
    "\n",
    "### YOLOv8 (You Only Look Once v8)\n",
    "- **Ventajas:**\n",
    "  - Detección en tiempo real (hasta 140 FPS)\n",
    "  - Alta precisión (mAP > 50%)\n",
    "  - Pre-entrenado en COCO dataset\n",
    "  - Fácil de usar con Ultralytics\n",
    "  \n",
    "### OpenCV (Open Computer Vision)\n",
    "- Estándar en visión por computadora\n",
    "- Amplia comunidad y documentación\n",
    "- Funciones optimizadas para imágenes y video\n",
    "\n",
    "### NumPy\n",
    "- Operaciones matriciales eficientes\n",
    "- Base para procesamiento numérico en Python\n",
    "- Compatible con OpenCV y frameworks de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f511508",
   "metadata": {},
   "source": [
    "# 3. Dataset COCO (Common Objects in Context)\n",
    "\n",
    "## ¿Qué es COCO?\n",
    "\n",
    "**COCO** es uno de los datasets más importantes para visión por computadora, creado por Microsoft Research.\n",
    "\n",
    "### Características principales:\n",
    "- **330,000+ imágenes** con escenas del mundo real\n",
    "- **80 categorías** de objetos (personas, vehículos, animales, etc.)\n",
    "- **1.5 millones** de instancias anotadas\n",
    "- Anotaciones precisas con bounding boxes y segmentación\n",
    "\n",
    "## ¿Cómo usamos COCO en este proyecto?\n",
    "\n",
    "### 1. Imágenes de Ejemplo\n",
    "Utilizamos **15 imágenes de tráfico de COCO** alojadas en Flickr:\n",
    "```python\n",
    "URLs = [\n",
    "    \"http://farm7.staticflickr.com/6035/6292445906_dcb4133c67_z.jpg\",\n",
    "    \"http://farm6.staticflickr.com/5022/5679421199_fea112b087_z.jpg\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "### 2. Modelo Pre-entrenado\n",
    "YOLOv8 viene **pre-entrenado en COCO**, lo que significa:\n",
    "- Ya conoce las 80 clases de COCO\n",
    "- No necesitamos entrenar desde cero\n",
    "- Funciona inmediatamente para nuestro caso de uso\n",
    "\n",
    "### 3. Clases que Usamos\n",
    "\n",
    "De las 80 clases de COCO, utilizamos:\n",
    "\n",
    "| ID | Clase | Uso en Proyecto |\n",
    "|----|-------|-----------------|\n",
    "| 0 | person | Control de aforo |\n",
    "| 1 | bicycle | Flujo vehicular |\n",
    "| 2 | car | Flujo vehicular |\n",
    "| 3 | motorcycle | Flujo vehicular |\n",
    "| 5 | bus | Flujo vehicular |\n",
    "| 7 | truck | Flujo vehicular |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91671744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando imagen de ejemplo de COCO...\n",
      "Imagen descargada: 640x473 píxeles\n",
      "   Canales: 3 (BGR)\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: Cómo descargamos imágenes de COCO desde Flickr\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def download_image(url):\n",
    "    \"\"\"\n",
    "    Descarga una imagen desde URL y la convierte a formato OpenCV\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL de la imagen en Flickr\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Imagen en formato BGR para OpenCV\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Hacer petición HTTP con timeout\n",
    "        response = requests.get(url, timeout=10)\n",
    "        \n",
    "        # Verificar que la descarga fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Convertir bytes a imagen PIL\n",
    "            image = Image.open(io.BytesIO(response.content))\n",
    "            \n",
    "            # Convertir de RGB (PIL) a BGR (OpenCV)\n",
    "            image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            return image_cv\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error descargando: {e}\")\n",
    "        return None\n",
    "\n",
    "# Lista de URLs de imágenes COCO\n",
    "def get_coco_traffic_images():\n",
    "    \"\"\"Retorna lista de 15 URLs de imágenes de tráfico de COCO\"\"\"\n",
    "    return [\n",
    "        \"http://farm7.staticflickr.com/6035/6292445906_dcb4133c67_z.jpg\",\n",
    "        \"http://farm6.staticflickr.com/5022/5679421199_fea112b087_z.jpg\", \n",
    "        \"http://farm9.staticflickr.com/8263/8703641816_80c3673de3_z.jpg\",\n",
    "        # ... más URLs\n",
    "    ]\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"Descargando imagen de ejemplo de COCO...\")\n",
    "url_ejemplo = \"http://farm7.staticflickr.com/6035/6292445906_dcb4133c67_z.jpg\"\n",
    "imagen = download_image(url_ejemplo)\n",
    "\n",
    "if imagen is not None:\n",
    "    print(f\"Imagen descargada: {imagen.shape[1]}x{imagen.shape[0]} píxeles\")\n",
    "    print(f\"   Canales: {imagen.shape[2]} (BGR)\")\n",
    "else:\n",
    "    print(\"Error al descargar imagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d462dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.13.0.92-cp37-abi3-win_amd64.whl (40.2 MB)\n",
      "     --------------------------------------- 40.2/40.2 MB 38.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (2.3.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.13.0.92\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d764690",
   "metadata": {},
   "source": [
    "# 4. YOLO (You Only Look Once) v8\n",
    "\n",
    "## ¿Qué es YOLO?\n",
    "\n",
    "**YOLO** es una familia de modelos de detección de objetos que revolucionó la visión por computadora por su:\n",
    "- **Velocidad**: Procesa imágenes en tiempo real\n",
    "- **Precisión**: Alta exactitud en detección\n",
    "- **Una sola pasada**: A diferencia de otros modelos, YOLO analiza la imagen completa de una vez\n",
    "\n",
    "## Evolución de YOLO\n",
    "\n",
    "```\n",
    "YOLOv1 (2016) → YOLOv2 → YOLOv3 → YOLOv4 → YOLOv5 → YOLOv6 → YOLOv7 → YOLOv8 (2023)\n",
    "```\n",
    "\n",
    "**YOLOv8** es la versión más reciente desarrollada por Ultralytics con mejoras en:\n",
    "- Arquitectura más eficiente\n",
    "- Mejores métricas de precisión\n",
    "- API más fácil de usar\n",
    "- Soporte para múltiples tareas (detección, segmentación, clasificación)\n",
    "\n",
    "## ¿Cómo funciona YOLO?\n",
    "\n",
    "### Proceso de Detección:\n",
    "\n",
    "1. **Entrada**: Imagen completa (ej: 640x640 píxeles)\n",
    "2. **Red Neuronal Convolucional**: Procesa la imagen en una sola pasada\n",
    "3. **Grid de Predicciones**: Divide la imagen en una cuadrícula (ej: 80x80)\n",
    "4. **Bounding Boxes**: Cada celda predice cajas delimitadoras\n",
    "5. **Clasificación**: Asigna probabilidades a cada clase\n",
    "6. **NMS (Non-Maximum Suppression)**: Elimina detecciones duplicadas\n",
    "7. **Salida**: Lista de objetos detectados con:\n",
    "   - Coordenadas del bounding box (x, y, width, height)\n",
    "   - Clase del objeto (persona, auto, etc.)\n",
    "   - Confianza (0-1)\n",
    "\n",
    "## Modelo que usamos: YOLOv8n\n",
    "\n",
    "**yolov8n.pt** = YOLOv8 Nano\n",
    "- Balance entre velocidad y precisión\n",
    "- Tamaño: ~6MB\n",
    "- Muy rápido en inferencia\n",
    "- Pre-entrenado en COCO (80 clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba13ed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.4.13-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 12.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.13.0.92)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.16.1)\n",
      "Collecting torch>=1.8.0\n",
      "  Downloading torch-2.10.0-cp311-cp311-win_amd64.whl (113.7 MB)\n",
      "     ------------------------------------- 113.7/113.7 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting torchvision>=0.9.0\n",
      "  Downloading torchvision-0.25.0-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "     ---------------------------------------- 4.0/4.0 MB 42.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Collecting polars>=0.20.0\n",
      "  Downloading polars-1.38.1-py3-none-any.whl (810 kB)\n",
      "     ------------------------------------- 810.4/810.4 kB 50.0 MB/s eta 0:00:00\n",
      "Collecting ultralytics-thop>=2.0.18\n",
      "  Using cached ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Collecting polars-runtime-32==1.38.1\n",
      "  Downloading polars_runtime_32-1.38.1-cp310-abi3-win_amd64.whl (45.7 MB)\n",
      "     --------------------------------------- 45.7/45.7 MB 27.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 33.5 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.5.1\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 43.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Collecting fsspec>=0.8.5\n",
      "  Downloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "     ------------------------------------- 202.5/202.5 kB 12.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Installing collected packages: mpmath, sympy, polars-runtime-32, networkx, fsspec, filelock, torch, polars, ultralytics-thop, torchvision, ultralytics\n",
      "Successfully installed filelock-3.20.3 fsspec-2026.2.0 mpmath-1.3.0 networkx-3.6.1 polars-1.38.1 polars-runtime-32-1.38.1 sympy-1.14.0 torch-2.10.0 torchvision-0.25.0 ultralytics-8.4.13 ultralytics-thop-2.0.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6aac043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo YOLOv8n...\n",
      "Modelo cargado exitosamente\n",
      "\n",
      "Clases que detectamos:\n",
      "   ID 0: persona\n",
      "   ID 1: bicicleta\n",
      "   ID 2: auto\n",
      "   ID 3: motocicleta\n",
      "   ID 5: autobus\n",
      "   ID 7: camion\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: Cómo usamos YOLOv8 para detección de objetos\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Cargar el modelo pre-entrenado\n",
    "print(\"Cargando modelo YOLOv8n...\")\n",
    "modelo = YOLO(\"yolov8n.pt\")\n",
    "print(\"Modelo cargado exitosamente\\n\")\n",
    "\n",
    "# 2. Configurar parámetros de detección\n",
    "CONFIDENCE_THRESHOLD = 0.65  # Umbral de confianza (65%)\n",
    "MIN_AREA = 300  # Área mínima para filtrar detecciones pequeñas\n",
    "\n",
    "# 3. Detectar objetos en una imagen\n",
    "def detectar_objetos(imagen, confidence=0.65):\n",
    "    \"\"\"\n",
    "    Realiza detección de objetos usando YOLOv8\n",
    "    \n",
    "    Args:\n",
    "        imagen: Imagen en formato numpy array (BGR)\n",
    "        confidence: Umbral de confianza mínimo\n",
    "        \n",
    "    Returns:\n",
    "        results: Objeto Results de Ultralytics con detecciones\n",
    "    \"\"\"\n",
    "    # Ejecutar detección (verbose=False para no mostrar logs)\n",
    "    results = modelo(imagen, conf=confidence, verbose=False)\n",
    "    return results\n",
    "\n",
    "# 4. Procesar resultados\n",
    "def procesar_detecciones(results):\n",
    "    \"\"\"\n",
    "    Extrae información útil de las detecciones\n",
    "    \n",
    "    Returns:\n",
    "        Lista de diccionarios con información de cada detección\n",
    "    \"\"\"\n",
    "    detecciones = []\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for box in boxes:\n",
    "                # Extraer información\n",
    "                class_id = int(box.cls.cpu().numpy()[0])\n",
    "                confidence = float(box.conf.cpu().numpy()[0])\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                \n",
    "                # Calcular área\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                # Filtrar por área mínima\n",
    "                if area >= MIN_AREA:\n",
    "                    detecciones.append({\n",
    "                        'class_id': class_id,\n",
    "                        'confidence': confidence,\n",
    "                        'bbox': (int(x1), int(y1), int(x2), int(y2)),\n",
    "                        'area': area\n",
    "                    })\n",
    "    \n",
    "    return detecciones\n",
    "\n",
    "# Ejemplo de clases COCO que usamos\n",
    "CLASES_USADAS = {\n",
    "    0: 'persona',\n",
    "    1: 'bicicleta',\n",
    "    2: 'auto',\n",
    "    3: 'motocicleta',\n",
    "    5: 'autobus',\n",
    "    7: 'camion'\n",
    "}\n",
    "\n",
    "print(\"Clases que detectamos:\")\n",
    "for id_clase, nombre in CLASES_USADAS.items():\n",
    "    print(f\"   ID {id_clase}: {nombre}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed9043",
   "metadata": {},
   "source": [
    "# 5. Arquitectura del Sistema\n",
    "\n",
    "## Diagrama de Flujo General\n",
    "\n",
    "```\n",
    "┌─────────────────┐\n",
    "│  Imagen COCO    │\n",
    "│  (Flickr URL)   │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│  Descargar      │\n",
    "│  Imagen         │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│  YOLOv8         │\n",
    "│  Detección      │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│  Filtrado       │\n",
    "│  (confianza,    │\n",
    "│   área mínima)  │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│  Tracking       │\n",
    "│  (ObjectTracker)│\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│  Análisis       │\n",
    "│  (Aforo/Flujo)  │\n",
    "└────────┬────────┘\n",
    "         │\n",
    "         ▼\n",
    "┌─────────────────┐\n",
    "│  Visualización  │\n",
    "│  (OpenCV)       │\n",
    "└─────────────────┘\n",
    "```\n",
    "\n",
    "## Componentes Principales\n",
    "\n",
    "### 1. Sistema de Detección (YOLOv8)\n",
    "```python\n",
    "imagen → YOLO → detecciones (bbox, clase, confianza)\n",
    "```\n",
    "\n",
    "### 2. Sistema de Tracking (ObjectTracker)\n",
    "- **Función**: Mantener IDs únicos para objetos entre frames\n",
    "- **Algoritmo**: Basado en centroides y distancia euclidiana\n",
    "- **Características**:\n",
    "  - Asigna ID único a cada objeto nuevo\n",
    "  - Rastrea movimiento usando centroides\n",
    "  - Mantiene historial de trayectorias\n",
    "  - Elimina objetos que \"desaparecen\"\n",
    "\n",
    "### 3. Sistema de Análisis\n",
    "- **AforoAnalyzer**: Cuenta personas, compara con capacidad\n",
    "- **FlujoVehicularAnalyzer**: Cuenta vehículos, clasifica tráfico\n",
    "\n",
    "### 4. Sistema de Visualización\n",
    "- Dibuja bounding boxes de colores\n",
    "- Muestra IDs y trayectorias\n",
    "- Paneles informativos\n",
    "- Indicadores visuales (semáforos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06e6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectTracker implementado\n",
      "Funcionalidades:\n",
      "   - Rastreo por centroides\n",
      "   - IDs únicos persistentes\n",
      "   - Trayectorias (trails)\n",
      "   - Manejo de objetos perdidos\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo: Sistema de Tracking de Objetos\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "class ObjectTracker:\n",
    "    \"\"\"\n",
    "    Clase para rastrear objetos usando centroide y distancia euclidiana\n",
    "    \n",
    "    Características:\n",
    "    - Asigna IDs únicos a nuevos objetos\n",
    "    - Mantiene trayectorias (trails)\n",
    "    - Elimina objetos que desaparecen\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_distance=80, max_disappeared=4):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_distance: Distancia máxima para considerar que es el mismo objeto\n",
    "            max_disappeared: Frames antes de eliminar un objeto\n",
    "        \"\"\"\n",
    "        self.next_id = 0  # Próximo ID a asignar\n",
    "        self.objects = {}  # Diccionario de objetos trackeados\n",
    "        self.disappeared = {}  # Contador de frames desaparecidos\n",
    "        self.max_distance = max_distance\n",
    "        self.max_disappeared = max_disappeared\n",
    "    \n",
    "    def register(self, centroid, class_id, confidence):\n",
    "        \"\"\"Registra un nuevo objeto\"\"\"\n",
    "        self.objects[self.next_id] = {\n",
    "            'centroid': centroid,\n",
    "            'class_id': class_id,\n",
    "            'confidence': confidence,\n",
    "            'trail': [centroid]  # Historial de posiciones\n",
    "        }\n",
    "        self.disappeared[self.next_id] = 0\n",
    "        self.next_id += 1\n",
    "    \n",
    "    def deregister(self, object_id):\n",
    "        \"\"\"Elimina un objeto del tracker\"\"\"\n",
    "        del self.objects[object_id]\n",
    "        del self.disappeared[object_id]\n",
    "    \n",
    "    def update(self, detections):\n",
    "        \"\"\"\n",
    "        Actualiza el tracker con nuevas detecciones\n",
    "        \n",
    "        Args:\n",
    "            detections: Lista de tuplas (centroid, class_id, confidence)\n",
    "            \n",
    "        Returns:\n",
    "            Dict con objetos actualizados {id: {centroid, class_id, ...}}\n",
    "        \"\"\"\n",
    "        # Si no hay detecciones, marcar todos como desaparecidos\n",
    "        if len(detections) == 0:\n",
    "            for object_id in list(self.disappeared.keys()):\n",
    "                self.disappeared[object_id] += 1\n",
    "                if self.disappeared[object_id] > self.max_disappeared:\n",
    "                    self.deregister(object_id)\n",
    "            return self.objects\n",
    "        \n",
    "        # Si no hay objetos previos, registrar todos\n",
    "        if len(self.objects) == 0:\n",
    "            for detection in detections:\n",
    "                centroid, class_id, confidence = detection\n",
    "                self.register(centroid, class_id, confidence)\n",
    "        else:\n",
    "            # Calcular matriz de distancias\n",
    "            object_ids = list(self.objects.keys())\n",
    "            object_centroids = [self.objects[oid]['centroid'] for oid in object_ids]\n",
    "            new_centroids = [d[0] for d in detections]\n",
    "            \n",
    "            # Distancia euclidiana entre todos los pares\n",
    "            D = dist.cdist(np.array(object_centroids), np.array(new_centroids))\n",
    "            \n",
    "            # Asignar detecciones a objetos existentes\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "            \n",
    "            used_rows = set()\n",
    "            used_cols = set()\n",
    "            \n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in used_rows or col in used_cols:\n",
    "                    continue\n",
    "                \n",
    "                if D[row, col] > self.max_distance:\n",
    "                    continue\n",
    "                \n",
    "                object_id = object_ids[row]\n",
    "                self.objects[object_id]['centroid'] = new_centroids[col]\n",
    "                self.objects[object_id]['confidence'] = detections[col][2]\n",
    "                self.objects[object_id]['trail'].append(new_centroids[col])\n",
    "                self.disappeared[object_id] = 0\n",
    "                \n",
    "                used_rows.add(row)\n",
    "                used_cols.add(col)\n",
    "            \n",
    "            # Nuevos objetos\n",
    "            for col in range(len(new_centroids)):\n",
    "                if col not in used_cols:\n",
    "                    self.register(new_centroids[col], detections[col][1], detections[col][2])\n",
    "            \n",
    "            # Objetos desaparecidos\n",
    "            for row in range(len(object_centroids)):\n",
    "                if row not in used_rows:\n",
    "                    object_id = object_ids[row]\n",
    "                    self.disappeared[object_id] += 1\n",
    "                    if self.disappeared[object_id] > self.max_disappeared:\n",
    "                        self.deregister(object_id)\n",
    "        \n",
    "        return self.objects\n",
    "\n",
    "print(\"ObjectTracker implementado\")\n",
    "print(\"Funcionalidades:\")\n",
    "print(\"   - Rastreo por centroides\")\n",
    "print(\"   - IDs únicos persistentes\")\n",
    "print(\"   - Trayectorias (trails)\")\n",
    "print(\"   - Manejo de objetos perdidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f75cd",
   "metadata": {},
   "source": [
    "# 6. Archivos del Proyecto\n",
    "\n",
    "## Estructura de Archivos\n",
    "\n",
    "```\n",
    "PROYECTO BASADAS P3 V2.0.0/\n",
    "│\n",
    "├── coco_traffic_improved.py    (Sistema completo con tracking)\n",
    "├── ejemplos_uso.py              (Casos de uso simplificados)\n",
    "├── requirements.txt             (Dependencias del proyecto)\n",
    "├── yolov8n.pt                   (Modelo YOLOv8 Nano pre-entrenado)\n",
    "└── INFORME_PROYECTO.ipynb       (Este documento)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## coco_traffic_improved.py\n",
    "\n",
    "**Propósito:** Sistema completo de detección y tracking con interfaz gráfica interactiva\n",
    "\n",
    "### Componentes:\n",
    "\n",
    "#### 1. Clase `ObjectTracker` (líneas 13-109)\n",
    "```python\n",
    "- register(): Registra nuevos objetos\n",
    "- deregister(): Elimina objetos\n",
    "- update(): Actualiza tracking con nuevas detecciones\n",
    "- reset(): Reinicia el sistema entre imágenes\n",
    "```\n",
    "\n",
    "#### 2. Clase `COCOTrafficAnalyzer` (líneas 112-492)\n",
    "```python\n",
    "- __init__(): Inicializa YOLO y tracking\n",
    "- reset_trackers(): Reinicia IDs entre imágenes\n",
    "- process_image(): Procesa una imagen con detección y tracking\n",
    "- draw_results(): Dibuja visualizaciones (boxes, IDs, trails)\n",
    "- analyze_images(): Procesa múltiples imágenes\n",
    "- run(): Ejecuta menú interactivo\n",
    "```\n",
    "\n",
    "### Características Principales:\n",
    "\n",
    "- **Tracking completo** con IDs únicos y trayectorias\n",
    "- **Filtrado inteligente** por confianza y área\n",
    "- **Umbrales específicos por clase**:\n",
    "  - Personas: 60%\n",
    "  - Bicicletas/Autos/Motos: 65%\n",
    "  - Buses/Camiones: 70%\n",
    "- **Visualización rica**: Bounding boxes, IDs, trails, estadísticas\n",
    "- **Menú interactivo** con múltiples opciones\n",
    "\n",
    "### ¿Cuándo usar este archivo?\n",
    "- Cuando necesites tracking detallado de objetos\n",
    "- Para análisis frame por frame con IDs persistentes\n",
    "- Experimentación y ajuste de parámetros\n",
    "\n",
    "---\n",
    "\n",
    "## ejemplos_uso.py\n",
    "\n",
    "**Propósito:** Casos de uso simplificados y prácticos para usuarios finales\n",
    "\n",
    "### Componentes:\n",
    "\n",
    "#### 1. Clase `AforoAnalyzer` (líneas 16-120)\n",
    "```python\n",
    "- analizar_imagen(): Cuenta personas\n",
    "- dibujar_resultado(): Visualiza con indicador verde/rojo\n",
    "```\n",
    "\n",
    "#### 2. Clase `FlujoVehicularAnalyzer` (líneas 123-260)\n",
    "```python\n",
    "- analizar_imagen(): Cuenta vehículos por tipo\n",
    "- dibujar_resultado(): Visualiza con semáforo de tráfico\n",
    "```\n",
    "\n",
    "### Características:\n",
    "\n",
    "- **Control de Aforo**:\n",
    "  - Entrada: Capacidad máxima (por consola)\n",
    "  - Salida: Verde (apto) / Rojo (excedido)\n",
    "  - Estadísticas finales\n",
    "  \n",
    "- **Flujo Vehicular**:\n",
    "  - Entrada: Umbral de congestión (por consola)\n",
    "  - Salida: Verde (fluido) / Amarillo (moderado) / Rojo (congestión)\n",
    "  - Desglose por tipo de vehículo\n",
    "\n",
    "- **Configuración flexible**:\n",
    "  - Selección de número de imágenes (1-15)\n",
    "  - Umbrales personalizables\n",
    "  - Resúmenes estadísticos\n",
    "\n",
    "### ¿Cuándo usar este archivo?\n",
    "- Para demostraciones rápidas\n",
    "- Casos de uso del mundo real (tiendas, calles)\n",
    "- Cuando no necesitas tracking detallado\n",
    "- Para presentaciones y pruebas de concepto\n",
    "\n",
    "---\n",
    "\n",
    "## requirements.txt\n",
    "\n",
    "**Propósito:** Lista de dependencias Python necesarias\n",
    "\n",
    "```txt\n",
    "ultralytics==8.4.12      # YOLOv8\n",
    "opencv-python==4.13.0.92 # Procesamiento de imágenes\n",
    "numpy==2.4.2             # Operaciones numéricas\n",
    "Pillow==12.1.0           # Manejo de imágenes\n",
    "matplotlib==3.10.8       # Gráficos\n",
    "scipy==1.17.0            # Cálculos científicos\n",
    "requests                 # Descargas HTTP\n",
    "```\n",
    "\n",
    "### Instalación:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## yolov8n.pt\n",
    "\n",
    "**Propósito:** Archivo de pesos del modelo YOLOv8 Nano\n",
    "\n",
    "- **Tamaño:** ~6 MB\n",
    "- **Arquitectura:** YOLOv8n (Nano - versión más ligera)\n",
    "- **Pre-entrenamiento:** COCO dataset (80 clases)\n",
    "- **Formato:** PyTorch (.pt)\n",
    "- **Proveedor:** Ultralytics\n",
    "\n",
    "### Clases detectables (extracto):\n",
    "- 0: person\n",
    "- 1: bicycle\n",
    "- 2: car\n",
    "- 3: motorcycle\n",
    "- 5: bus\n",
    "- 7: truck\n",
    "- ... (hasta 80 clases)\n",
    "\n",
    "---\n",
    "\n",
    "## Comparación de Archivos\n",
    "\n",
    "| Característica | coco_traffic_improved.py | ejemplos_uso.py |\n",
    "|----------------|--------------------------|-----------------|\n",
    "| **Complejidad** | Alta | Baja |\n",
    "| **Tracking** | Sí (con IDs) | No |\n",
    "| **Trayectorias** | Sí | No |\n",
    "| **Interfaz** | Menú interactivo | Casos de uso directos |\n",
    "| **Configuración** | Código | Consola (interactivo) |\n",
    "| **Visualización** | Detallada | Simplificada |\n",
    "| **Uso ideal** | Desarrollo/Análisis | Demostración/Producción |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3cdfe3",
   "metadata": {},
   "source": [
    "# 7. Instalación y Configuración\n",
    "\n",
    "## Para Google Colab\n",
    "\n",
    "### Paso 1: Instalar Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c1c1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (22.3)\n",
      "Collecting pip\n",
      "  Using cached pip-26.0.1-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics==8.4.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.4.12)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (2.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (3.10.8)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (4.13.0.92)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (12.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (1.17.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (2.10.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (0.25.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (7.0.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (1.38.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics==8.4.12) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.4.12) (2.9.0.post0)\n",
      "Requirement already satisfied: polars-runtime-32==1.38.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from polars>=0.20.0->ultralytics==8.4.12) (1.38.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.12) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.12) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.12) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.4.12) (2025.7.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.4.12) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.4.12) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.4.12) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.4.12) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.4.12) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.4.12) (2026.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.4.12) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics==8.4.12) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.4.12) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.13.0.92 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.0.92)\n",
      "Requirement already satisfied: numpy>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python==4.13.0.92) (2.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow==12.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (12.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.10.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib==3.10.8) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.10.8) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.17.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy<2.7,>=1.26.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy==1.17.0) (2.4.2)\n",
      "\n",
      "Todas las dependencias instaladas correctamente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar esto en Google Colab para instalar todas las dependencias\n",
    "\n",
    "# Actualizar pip\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Instalar librerías necesarias\n",
    "!pip install ultralytics==8.4.12\n",
    "!pip install opencv-python==4.13.0.92\n",
    "!pip install numpy==2.4.2\n",
    "!pip install Pillow==12.1.0\n",
    "!pip install matplotlib==3.10.8\n",
    "!pip install scipy==1.17.0\n",
    "\n",
    "print(\"\\nTodas las dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1281c",
   "metadata": {},
   "source": [
    "### Paso 2: Descargar el Modelo YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c61ba69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando modelo YOLOv8n...\n",
      "Modelo descargado y listo para usar\n"
     ]
    }
   ],
   "source": [
    "# Descargar modelo YOLOv8n (se descarga automáticamente la primera vez)\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"Descargando modelo YOLOv8n...\")\n",
    "modelo = YOLO(\"yolov8n.pt\")\n",
    "print(\"Modelo descargado y listo para usar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb3fc0",
   "metadata": {},
   "source": [
    "# 8. Ejemplos Prácticos de Uso\n",
    "\n",
    "## Ejemplo 1: Detección Básica con YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9baa6dfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpatches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow  \u001b[38;5;66;03m# Para mostrar imágenes en Colab\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Cargar modelo\u001b[39;00m\n\u001b[32m     12\u001b[39m modelo = YOLO(\u001b[33m\"\u001b[39m\u001b[33myolov8n.pt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Ejemplo completo: Detectar objetos en una imagen de COCO\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "from google.colab.patches import cv2_imshow  # Para mostrar imágenes en Colab\n",
    "\n",
    "# Cargar modelo\n",
    "modelo = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Descargar imagen de ejemplo\n",
    "url = \"http://farm7.staticflickr.com/6035/6292445906_dcb4133c67_z.jpg\"\n",
    "response = requests.get(url, timeout=10)\n",
    "imagen_pil = Image.open(io.BytesIO(response.content))\n",
    "imagen = cv2.cvtColor(np.array(imagen_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "print(f\"Imagen cargada: {imagen.shape[1]}x{imagen.shape[0]} píxeles\\n\")\n",
    "\n",
    "# Realizar detección\n",
    "results = modelo(imagen, conf=0.6, verbose=False)\n",
    "\n",
    "# Procesar resultados\n",
    "print(\"Objetos detectados:\\n\")\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            # Extraer información\n",
    "            class_id = int(box.cls.cpu().numpy()[0])\n",
    "            class_name = modelo.names[class_id]\n",
    "            confidence = float(box.conf.cpu().numpy()[0])\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            \n",
    "            # Mostrar en consola\n",
    "            print(f\"└─ {class_name}: {confidence:.2%} confianza\")\n",
    "            \n",
    "            # Dibujar bounding box\n",
    "            cv2.rectangle(imagen, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(imagen, f\"{class_name} {confidence:.2f}\", \n",
    "                       (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Mostrar imagen con deteccionesprint(\"\\nResultado visual:\")\n",
    "cv2_imshow(imagen)  # En Colab\n",
    "# cv2.imshow(\"Detecciones\", imagen); cv2.waitKey(0)  # En local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30affe0",
   "metadata": {},
   "source": [
    "## Ejemplo 2: Control de Aforo\n",
    "\n",
    "Cuenta personas y determina si se excede la capacidad máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb17c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Sistema de Control de Aforo\n",
    "\n",
    "# Configuración\n",
    "CAPACIDAD_MAXIMA = 10  # Personas permitidas\n",
    "CONFIDENCE_PERSONAS = 0.60  # Umbral para detectar personas\n",
    "\n",
    "# Cargar imagen\n",
    "url = \"http://farm9.staticflickr.com/8263/8703641816_80c3673de3_z.jpg\"\n",
    "response = requests.get(url, timeout=10)\n",
    "imagen = cv2.cvtColor(np.array(Image.open(io.BytesIO(response.content))), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Detectar solo personas (class_id = 0)\n",
    "results = modelo(imagen, conf=CONFIDENCE_PERSONAS, classes=[0], verbose=False)\n",
    "\n",
    "# Contar personas\n",
    "personas_count = 0\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "            \n",
    "            # Filtrar por área mínima\n",
    "            if area >= 300:\n",
    "                personas_count += 1\n",
    "                confidence = float(box.conf.cpu().numpy()[0])\n",
    "                \n",
    "                # Dibujar\n",
    "                cv2.rectangle(imagen, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(imagen, f\"Persona {confidence:.2f}\", \n",
    "                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Determinar estado\n",
    "porcentaje = (personas_count / CAPACIDAD_MAXIMA) * 100\n",
    "estado = \"VERDE\" if personas_count < CAPACIDAD_MAXIMA else \"ROJO\"\n",
    "color_semaforo = (0, 255, 0) if  personas_count < CAPACIDAD_MAXIMA else (0, 0, 255)\n",
    "\n",
    "# Panel de información\n",
    "cv2.rectangle(imagen, (10, 10), (400, 140), (0, 0, 0), -1)\n",
    "cv2.rectangle(imagen, (10, 10), (400, 140), (255, 255, 255), 2)\n",
    "cv2.putText(imagen, \"CONTROL DE AFORO\", (20, 40), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "cv2.putText(imagen, f\"Personas: {personas_count}\", (20, 75), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "cv2.putText(imagen, f\"Capacidad: {CAPACIDAD_MAXIMA}\", (20, 105), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "# Indicador visual (semáforo)\n",
    "w = imagen.shape[1]\n",
    "cv2.circle(imagen, (w-80, 70), 40, color_semaforo, -1)\n",
    "\n",
    "# Resultados en consola\n",
    "print(\"=\" * 50)\n",
    "print(\"CONTROL DE AFORO\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Personas detectadas: {personas_count}\")\n",
    "print(f\"Capacidad máxima: {CAPACIDAD_MAXIMA}\")\n",
    "print(f\"Ocupación: {porcentaje:.1f}%\")\n",
    "print(f\"Estado: {estado}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Mostrar resultado\n",
    "cv2_imshow(imagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdb0d5",
   "metadata": {},
   "source": [
    "## Ejemplo 3: Flujo Vehicular\n",
    "\n",
    "Detecta y clasifica vehículos, determinando el nivel de tráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0669e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FLUJO VEHICULAR\n",
      "==================================================\n",
      "Total vehículos: 1\n",
      "\n",
      "Desglose por tipo:\n",
      "  auto: 1\n",
      "\n",
      "Nivel de tráfico: FLUIDO\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv2_imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNivel de tráfico: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestado\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[43mcv2_imshow\u001b[49m(imagen)\n",
      "\u001b[31mNameError\u001b[39m: name 'cv2_imshow' is not defined"
     ]
    }
   ],
   "source": [
    "# Ejemplo: Sistema de Flujo Vehicular\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Configuración\n",
    "UMBRAL_CONGESTION = 8  # Número de vehículos para considerar congestión\n",
    "VEHICLE_CLASSES = {\n",
    "    2: 'auto',\n",
    "    3: 'motocicleta',\n",
    "    5: 'autobus',\n",
    "    7: 'camion'\n",
    "}\n",
    "COLORS = {\n",
    "    'auto': (0, 0, 255),\n",
    "    'motocicleta': (255, 0, 255),\n",
    "    'autobus': (0, 255, 255),\n",
    "    'camion': (255, 0, 0)\n",
    "}\n",
    "\n",
    "# Cargar imagen\n",
    "url = \"http://farm6.staticflickr.com/5022/5679421199_fea112b087_z.jpg\"\n",
    "response = requests.get(url,timeout=10)\n",
    "imagen = cv2.cvtColor(np.array(Image.open(io.BytesIO(response.content))), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Detectar vehículos (classes = IDs de vehículos en COCO)\n",
    "vehicle_ids = list(VEHICLE_CLASSES.keys())\n",
    "results = modelo(imagen, conf=0.65, classes=vehicle_ids, verbose=False)\n",
    "\n",
    "# Contar vehículos por tipo\n",
    "vehiculos_count = 0\n",
    "vehiculos_por_tipo = defaultdict(int)\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    if boxes is not None:\n",
    "        for box in boxes:\n",
    "            class_id = int(box.cls.cpu().numpy()[0])\n",
    "            tipo = VEHICLE_CLASSES[class_id]\n",
    "            confidence = float(box.conf.cpu().numpy()[0])\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            \n",
    "            area = (x2 - x1) * (y2 - y1)\n",
    "            if area >= 300:\n",
    "                vehiculos_count += 1\n",
    "                vehiculos_por_tipo[tipo] += 1\n",
    "                \n",
    "                # Dibujar\n",
    "                color = COLORS[tipo]\n",
    "                cv2.rectangle(imagen, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(imagen, f\"{tipo} {confidence:.2f}\", \n",
    "                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Determinar estado del tráfico\n",
    "if vehiculos_count < UMBRAL_CONGESTION * 0.5:\n",
    "    estado = \"FLUIDO\"\n",
    "    color_semaforo = (0, 255, 0)\n",
    "elif vehiculos_count < UMBRAL_CONGESTION:\n",
    "    estado = \"MODERADO\"\n",
    "    color_semaforo = (0, 255, 255)\n",
    "else:\n",
    "    estado = \"CONGESTIÓN\"\n",
    "    color_semaforo = (0, 0, 255)\n",
    "\n",
    "# Panel de información\n",
    "cv2.rectangle(imagen, (10, 10), (400, 180), (0, 0, 0), -1)\n",
    "cv2.rectangle(imagen, (10, 10), (400, 180), (255, 255, 255), 2)\n",
    "cv2.putText(imagen, \"FLUJO VEHICULAR\", (20, 40), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "cv2.putText(imagen, f\"Total: {vehiculos_count} vehiculos\", (20, 75), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "y = 105\n",
    "for tipo, count in vehiculos_por_tipo.items():\n",
    "    cv2.putText(imagen, f\"{tipo}: {count}\", (20, y), \n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[tipo], 2)\n",
    "    y += 25\n",
    "\n",
    "# Indicador visual (semáforo)\n",
    "w = imagen.shape[1]\n",
    "cv2.circle(imagen, (w-80, 90), 40, color_semaforo, -1)\n",
    "cv2.putText(imagen, estado, (w-120, 140), \n",
    "           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_semaforo, 2)\n",
    "\n",
    "# Resultados en consola\n",
    "print(\"=\" * 50)\n",
    "print(\"FLUJO VEHICULAR\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total vehículos: {vehiculos_count}\")\n",
    "print(f\"\\nDesglose por tipo:\")\n",
    "for tipo, count in vehiculos_por_tipo.items():\n",
    "    print(f\"  {tipo}: {count}\")\n",
    "print(f\"\\nNivel de tráfico: {estado}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cv2_imshow(imagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a8eee",
   "metadata": {},
   "source": [
    "# 8.5. Métricas de Evaluación Implementadas\n",
    "\n",
    "## ¿Qué son las métricas de evaluación?\n",
    "\n",
    "Las **métricas de evaluación** son herramientas cuantitativas que nos permiten medir objetivamente qué tan bien funciona nuestro sistema de detección de objetos. Son fundamentales para:\n",
    "\n",
    "- **Evaluar precisión**: ¿Qué tan exacto es nuestro modelo?\n",
    "- **Comparar métodos**: ¿Cuál algoritmo es mejor?\n",
    "- **Optimizar parámetros**: ¿Qué configuración da mejores resultados?\n",
    "- **Validar científicamente**: Proporcionar evidencia cuantitativa del rendimiento\n",
    "\n",
    "---\n",
    "\n",
    "## Métricas Implementadas en Nuestro Proyecto\n",
    "\n",
    "### 1. Intersection over Union (IoU)\n",
    "\n",
    "**¿Qué es?**  \n",
    "IoU mide qué tan bien se **superponen** dos cajas delimitadoras (bounding boxes): la predicción de nuestro modelo vs. la verdad de terreno (ground truth).\n",
    "\n",
    "**Fórmula matemática:**\n",
    "$$IoU = \\frac{\\text{Área de Intersección}}{\\text{Área de Unión}} = \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "\n",
    "**Interpretación:**\n",
    "- **IoU = 1.0**: Perfecto (cajas idénticas)\n",
    "- **IoU = 0.5**: Umbral típico para considerar detección correcta\n",
    "- **IoU = 0.0**: Sin superposición (detección fallida)\n",
    "\n",
    "**Implementación en nuestro código:**\n",
    "```python\n",
    "def calculate_iou(self, box1, box2):\n",
    "    \"\"\"Calcula IoU entre dos bounding boxes\"\"\"\n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    # Área de intersección\n",
    "    x1_i = max(x1_1, x1_2)\n",
    "    y1_i = max(y1_1, y1_2)\n",
    "    x2_i = min(x2_1, x2_2)\n",
    "    y2_i = min(y2_1, y2_2)\n",
    "    \n",
    "    if x2_i <= x1_i or y2_i <= y1_i:\n",
    "        return 0.0  # No hay intersección\n",
    "        \n",
    "    intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "    \n",
    "    # Área de unión\n",
    "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Confusion Matrix y Métricas Derivadas\n",
    "\n",
    "**¿Qué es una Confusion Matrix?**  \n",
    "Es una tabla que permite visualizar el rendimiento de un algoritmo de clasificación:\n",
    "\n",
    "|                | Predicción Positiva | Predicción Negativa |\n",
    "|----------------|-------------------|-------------------|\n",
    "| **Real Positivo** | True Positive (TP) | False Negative (FN) |\n",
    "| **Real Negativo** | False Positive (FP) | True Negative (TN) |\n",
    "\n",
    "**En nuestro contexto:**\n",
    "- **True Positive (TP)**: Detección correcta (IoU ≥ 0.5 con ground truth)\n",
    "- **False Positive (FP)**: Detección incorrecta (no hay objeto o IoU < 0.5)\n",
    "- **False Negative (FN)**: Objeto no detectado (existe pero no lo encontramos)\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Precision (Precisión)\n",
    "\n",
    "**Definición:**  \n",
    "De todas las detecciones que hice, ¿qué porcentaje son correctas?\n",
    "\n",
    "**Fórmula:**\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**Interpretación:**\n",
    "- **Alta precisión**: Pocas detecciones falsas (el modelo es \"cuidadoso\")\n",
    "- **Baja precisión**: Muchas detecciones falsas (el modelo es \"descuidado\")\n",
    "\n",
    "**Ejemplo práctico:**\n",
    "- Si detecté 100 autos y 85 eran realmente autos → Precision = 85%\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Recall (Rellamada/Sensibilidad)\n",
    "\n",
    "**Definición:**  \n",
    "De todos los objetos que realmente existen, ¿qué porcentaje detecté?\n",
    "\n",
    "**Fórmula:**\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**Interpretación:**\n",
    "- **Alto recall**: Pocas detecciones perdidas (el modelo es \"completo\")\n",
    "- **Bajo recall**: Muchas detecciones perdidas (el modelo es \"incompleto\")\n",
    "\n",
    "**Ejemplo práctico:**\n",
    "- Si había 80 personas en la imagen y detecté 72 → Recall = 90%\n",
    "\n",
    "---\n",
    "\n",
    "### 5. F1-Score\n",
    "\n",
    "**Definición:**  \n",
    "Media armónica entre Precision y Recall. Balancea ambas métricas.\n",
    "\n",
    "**Fórmula:**\n",
    "$$F1\\text{-}Score = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$$\n",
    "\n",
    "**Interpretación:**\n",
    "- **F1 = 1.0**: Perfecto balance (precisión y recall altos)\n",
    "- **F1 = 0.0**: Rendimiento muy malo\n",
    "- **F1 ≈ 0.8-0.9**: Excelente rendimiento para aplicaciones reales\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Average Precision (AP)\n",
    "\n",
    "**Definición:**  \n",
    "Área bajo la curva Precision-Recall. Métrica estándar en COCO dataset.\n",
    "\n",
    "**Cálculo:**\n",
    "1. Ordenar detecciones por confianza (descendente)\n",
    "2. Para cada umbral de confianza, calcular Precision y Recall\n",
    "3. Graficar curva Precision vs Recall\n",
    "4. Calcular área bajo la curva\n",
    "\n",
    "**Variantes:**\n",
    "- **AP@0.5**: AP con umbral IoU = 0.5\n",
    "- **AP@0.75**: AP con umbral IoU = 0.75 (más estricto)\n",
    "- **mAP**: Promedio de AP across todas las clases\n",
    "\n",
    "---\n",
    "\n",
    "## Implementación Completa en Nuestro Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68184018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación completa de la clase MetricsCalculator\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class MetricsCalculator:\n",
    "    \"\"\"\n",
    "    Calculadora de métricas de evaluación para detección de objetos.\n",
    "    Implementa estándares COCO: IoU, Precision, Recall, F1-Score, AP\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total_tp = 0  # True Positives totales\n",
    "        self.total_fp = 0  # False Positives totales\n",
    "        self.total_fn = 0  # False Negatives totales\n",
    "        self.total_iou = []  # Lista de valores IoU\n",
    "        \n",
    "        # Métricas por clase\n",
    "        self.class_metrics = defaultdict(lambda: {\n",
    "            'tp': 0, 'fp': 0, 'fn': 0, 'iou_values': []\n",
    "        })\n",
    "        \n",
    "    def calculate_iou(self, box1, box2):\n",
    "        \"\"\"\n",
    "        Calcula Intersection over Union entre dos bounding boxes\n",
    "        \n",
    "        Args:\n",
    "            box1, box2: Tuplas (x1, y1, x2, y2)\n",
    "            \n",
    "        Returns:\n",
    "            float: Valor IoU entre 0.0 y 1.0\n",
    "        \"\"\"\n",
    "        x1_1, y1_1, x2_1, y2_1 = box1\n",
    "        x1_2, y1_2, x2_2, y2_2 = box2\n",
    "        \n",
    "        # Coordenadas de intersección\n",
    "        x1_i = max(x1_1, x1_2)\n",
    "        y1_i = max(y1_1, y1_2)\n",
    "        x2_i = min(x2_1, x2_2)\n",
    "        y2_i = min(y2_1, y2_2)\n",
    "        \n",
    "        # Verificar si hay intersección\n",
    "        if x2_i <= x1_i or y2_i <= y1_i:\n",
    "            return 0.0\n",
    "            \n",
    "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
    "        \n",
    "        # Áreas individuales\n",
    "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
    "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
    "        union = area1 + area2 - intersection\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def evaluate_detections(self, predictions, ground_truth, iou_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Evalúa detecciones comparando con ground truth\n",
    "        \n",
    "        Args:\n",
    "            predictions: Lista de detecciones del modelo\n",
    "                        [{'bbox': (x1,y1,x2,y2), 'class_id': int, 'confidence': float}]\n",
    "            ground_truth: Lista de anotaciones verdaderas\n",
    "                         [{'bbox': (x1,y1,x2,y2), 'class_id': int}]\n",
    "            iou_threshold: Umbral IoU para considerar match válido (típicamente 0.5)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Casos especiales\n",
    "        if len(ground_truth) == 0:\n",
    "            self.total_fp += len(predictions)\n",
    "            return\n",
    "            \n",
    "        if len(predictions) == 0:\n",
    "            self.total_fn += len(ground_truth)\n",
    "            return\n",
    "            \n",
    "        # Crear matriz de IoU entre todas las predicciones y ground truth\n",
    "        iou_matrix = np.zeros((len(predictions), len(ground_truth)))\n",
    "        \n",
    "        for i, pred in enumerate(predictions):\n",
    "            for j, gt in enumerate(ground_truth):\n",
    "                # Solo calcular IoU si es la misma clase\n",
    "                if pred.get('class_id') == gt.get('class_id'):\n",
    "                    iou = self.calculate_iou(pred['bbox'], gt['bbox'])\n",
    "                    iou_matrix[i][j] = iou\n",
    "                    \n",
    "                    # Almacenar IoU para estadísticas\n",
    "                    if iou > 0:\n",
    "                        self.total_iou.append(iou)\n",
    "                        class_id = pred['class_id']\n",
    "                        self.class_metrics[class_id]['iou_values'].append(iou)\n",
    "        \n",
    "        # Asignación greedy: emparejar predicciones con ground truth\n",
    "        used_gt = set()\n",
    "        used_pred = set()\n",
    "        \n",
    "        # Crear lista de matches ordenados por IoU descendente\n",
    "        matches = []\n",
    "        for i in range(len(predictions)):\n",
    "            for j in range(len(ground_truth)):\n",
    "                if iou_matrix[i][j] >= iou_threshold:\n",
    "                    matches.append((i, j, iou_matrix[i][j]))\n",
    "        \n",
    "        # Ordenar matches por IoU descendente\n",
    "        matches.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        # Asignar matches únicos (greedy assignment)\n",
    "        for pred_idx, gt_idx, iou_val in matches:\n",
    "            if pred_idx not in used_pred and gt_idx not in used_gt:\n",
    "                self.total_tp += 1\n",
    "                \n",
    "                # Métricas por clase\n",
    "                class_id = predictions[pred_idx]['class_id']\n",
    "                self.class_metrics[class_id]['tp'] += 1\n",
    "                \n",
    "                used_pred.add(pred_idx)\n",
    "                used_gt.add(gt_idx)\n",
    "        \n",
    "        # False Positives: predicciones no emparejadas\n",
    "        for i, pred in enumerate(predictions):\n",
    "            if i not in used_pred:\n",
    "                self.total_fp += 1\n",
    "                class_id = pred['class_id']\n",
    "                self.class_metrics[class_id]['fp'] += 1\n",
    "        \n",
    "        # False Negatives: ground truth no emparejado\n",
    "        for j, gt in enumerate(ground_truth):\n",
    "            if j not in used_gt:\n",
    "                self.total_fn += 1\n",
    "                class_id = gt['class_id']\n",
    "                self.class_metrics[class_id]['fn'] += 1\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"\n",
    "        Calcula y retorna todas las métricas de evaluación\n",
    "        \n",
    "        Returns:\n",
    "            dict: Diccionario con todas las métricas calculadas\n",
    "        \"\"\"\n",
    "        # Métricas globales\n",
    "        precision = self.total_tp / (self.total_tp + self.total_fp) if (self.total_tp + self.total_fp) > 0 else 0.0\n",
    "        recall = self.total_tp / (self.total_tp + self.total_fn) if (self.total_tp + self.total_fn) > 0 else 0.0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        avg_iou = np.mean(self.total_iou) if self.total_iou else 0.0\n",
    "        \n",
    "        # Métricas por clase\n",
    "        class_metrics_detailed = {}\n",
    "        for class_id, metrics in self.class_metrics.items():\n",
    "            tp, fp, fn = metrics['tp'], metrics['fp'], metrics['fn']\n",
    "            class_precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            class_recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall) if (class_precision + class_recall) > 0 else 0.0\n",
    "            class_iou = np.mean(metrics['iou_values']) if metrics['iou_values'] else 0.0\n",
    "            \n",
    "            class_metrics_detailed[class_id] = {\n",
    "                'precision': class_precision,\n",
    "                'recall': class_recall,\n",
    "                'f1_score': class_f1,\n",
    "                'avg_iou': class_iou,\n",
    "                'tp': tp,\n",
    "                'fp': fp,\n",
    "                'fn': fn\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            # Métricas globales\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'avg_iou': avg_iou,\n",
    "            'total_tp': self.total_tp,\n",
    "            'total_fp': self.total_fp,\n",
    "            'total_fn': self.total_fn,\n",
    "            \n",
    "            # Métricas por clase\n",
    "            'class_metrics': class_metrics_detailed,\n",
    "            \n",
    "            # Información adicional\n",
    "            'total_detections': self.total_tp + self.total_fp,\n",
    "            'total_ground_truth': self.total_tp + self.total_fn,\n",
    "            'num_iou_samples': len(self.total_iou)\n",
    "        }\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reinicia todas las métricas para nueva evaluación\"\"\"\n",
    "        self.total_tp = 0\n",
    "        self.total_fp = 0\n",
    "        self.total_fn = 0\n",
    "        self.total_iou.clear()\n",
    "        self.class_metrics.clear()\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"Imprime resumen detallado de métricas\"\"\"\n",
    "        metrics = self.get_metrics()\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"REPORTE DE MÉTRICAS DE EVALUACIÓN\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"MÉTRICAS GLOBALES:\")\n",
    "        print(f\"   Precision:     {metrics['precision']:.3f} ({metrics['precision']*100:.1f}%)\")\n",
    "        print(f\"   Recall:        {metrics['recall']:.3f} ({metrics['recall']*100:.1f}%)\")\n",
    "        print(f\"   F1-Score:      {metrics['f1_score']:.3f}\")\n",
    "        print(f\"   IoU Promedio:  {metrics['avg_iou']:.3f}\")\n",
    "        \n",
    "        print(f\"\\nCONTEOS:\")\n",
    "        print(f\"   True Positives:  {metrics['total_tp']}\")\n",
    "        print(f\"   False Positives: {metrics['total_fp']}\")\n",
    "        print(f\"   False Negatives: {metrics['total_fn']}\")\n",
    "        \n",
    "        # Mapeo de IDs a nombres de clases\n",
    "        class_names = {0: 'persona', 1: 'bicicleta', 2: 'auto', \n",
    "                      3: 'motocicleta', 5: 'autobus', 7: 'camion'}\n",
    "        \n",
    "        if metrics['class_metrics']:\n",
    "            print(f\"\\nMÉTRICAS POR CLASE:\")\n",
    "            for class_id, class_metrics in metrics['class_metrics'].items():\n",
    "                class_name = class_names.get(class_id, f\"clase_{class_id}\")\n",
    "                print(f\"   {class_name} (ID {class_id}):\")\n",
    "                print(f\"      Precision: {class_metrics['precision']:.3f} ({class_metrics['precision']*100:.1f}%)\")\n",
    "                print(f\"      Recall:    {class_metrics['recall']:.3f} ({class_metrics['recall']*100:.1f}%)\")\n",
    "                print(f\"      F1-Score:  {class_metrics['f1_score']:.3f}\")\n",
    "                print(f\"      TP: {class_metrics['tp']}, FP: {class_metrics['fp']}, FN: {class_metrics['fn']}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"MetricsCalculator implementado con funcionalidades completas:\")\n",
    "print(\"   - IoU calculation\")\n",
    "print(\"   - Precision, Recall, F1-Score\")\n",
    "print(\"   - Métricas por clase\")\n",
    "print(\"   - Evaluación vs ground truth\")\n",
    "print(\"   - Reportes detallados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a031d",
   "metadata": {},
   "source": [
    "## 8.6. Integración de Métricas en el Sistema de Análisis\n",
    "\n",
    "La integración de las métricas de evaluación en nuestro sistema proporciona retroalimentación continua sobre la calidad de las detecciones. A continuación se muestra cómo se utiliza en el contexto del análisis de tráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379603c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo práctico: Evaluación de detecciones en tiempo real\n",
    "\n",
    "# Simulación de casos de uso reales del sistema\n",
    "def simulate_traffic_evaluation():\n",
    "    \"\"\"\n",
    "    Simula evaluación de métricas en un escenario de tráfico real\n",
    "    Demuestra cómo se calculan las métricas con detecciones del modelo YOLOv8\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializar calculadora de métricas\n",
    "    metrics_calc = MetricsCalculator()\n",
    "    \n",
    "    # ESCENARIO 1: Intersección urbana congestionada\n",
    "    print(\"ESCENARIO 1: Intersección urbana - evaluación de detecciones\")\n",
    "    \n",
    "    # Ground Truth: Objetos realmente presentes en la imagen\n",
    "    ground_truth_frame1 = [\n",
    "        {'bbox': (100, 150, 200, 300), 'class_id': 0},  # persona\n",
    "        {'bbox': (250, 100, 400, 250), 'class_id': 2},  # auto\n",
    "        {'bbox': (450, 120, 580, 280), 'class_id': 2},  # auto\n",
    "        {'bbox': (50, 180, 120, 320), 'class_id': 1},   # bicicleta\n",
    "        {'bbox': (600, 80, 750, 200), 'class_id': 5}    # autobus\n",
    "    ]\n",
    "    \n",
    "    # Predicciones del modelo YOLOv8 (incluye confianza)\n",
    "    predictions_frame1 = [\n",
    "        {'bbox': (105, 155, 195, 295), 'class_id': 0, 'confidence': 0.92},  # persona (TP - buena detección)\n",
    "        {'bbox': (245, 95, 395, 245), 'class_id': 2, 'confidence': 0.88},   # auto (TP - buena detección)\n",
    "        {'bbox': (455, 125, 575, 275), 'class_id': 2, 'confidence': 0.85},  # auto (TP - buena detección)\n",
    "        {'bbox': (55, 175, 115, 315), 'class_id': 1, 'confidence': 0.78},   # bicicleta (TP - buena detección)\n",
    "        {'bbox': (700, 90, 800, 180), 'class_id': 2, 'confidence': 0.65},   # auto (FP - detección incorrecta)\n",
    "        {'bbox': (320, 50, 380, 90), 'class_id': 0, 'confidence': 0.72}     # persona (FP - no existe en GT)\n",
    "    ]\n",
    "    # Nota: El autobús en (600, 80, 750, 200) no fue detectado (FN)\n",
    "    \n",
    "    # Evaluar el frame\n",
    "    metrics_calc.evaluate_detections(predictions_frame1, ground_truth_frame1, iou_threshold=0.5)\n",
    "    \n",
    "    # ESCENARIO 2: Calle residencial (menos objetos)\n",
    "    print(\"\\nESCENARIO 2: Calle residencial - evaluación de detecciones\")\n",
    "    \n",
    "    ground_truth_frame2 = [\n",
    "        {'bbox': (150, 200, 300, 400), 'class_id': 0},  # persona paseando\n",
    "        {'bbox': (400, 180, 550, 320), 'class_id': 1},  # bicicleta\n",
    "        {'bbox': (600, 150, 800, 350), 'class_id': 2}   # auto estacionado\n",
    "    ]\n",
    "    \n",
    "    predictions_frame2 = [\n",
    "        {'bbox': (155, 205, 295, 395), 'class_id': 0, 'confidence': 0.94},  # persona (TP)\n",
    "        {'bbox': (405, 185, 545, 315), 'class_id': 1, 'confidence': 0.89},  # bicicleta (TP)\n",
    "        {'bbox': (605, 155, 795, 345), 'class_id': 2, 'confidence': 0.91}   # auto (TP)\n",
    "    ]\n",
    "    # Escenario perfecto: todas las detecciones son correctas\n",
    "    \n",
    "    metrics_calc.evaluate_detections(predictions_frame2, ground_truth_frame2, iou_threshold=0.5)\n",
    "    \n",
    "    # ESCENARIO 3: Hora pico con múltiples falsos positivos\n",
    "    print(\"\\nESCENARIO 3: Hora pico - múltiples detecciones\")\n",
    "    \n",
    "    ground_truth_frame3 = [\n",
    "        {'bbox': (80, 100, 180, 250), 'class_id': 2},   # auto 1\n",
    "        {'bbox': (200, 90, 320, 240), 'class_id': 2},   # auto 2\n",
    "        {'bbox': (350, 110, 480, 280), 'class_id': 5},  # autobus\n",
    "        {'bbox': (500, 120, 600, 270), 'class_id': 2},  # auto 3\n",
    "        {'bbox': (30, 200, 90, 350), 'class_id': 0}     # persona\n",
    "    ]\n",
    "    \n",
    "    predictions_frame3 = [\n",
    "        {'bbox': (85, 105, 175, 245), 'class_id': 2, 'confidence': 0.86},   # auto 1 (TP)\n",
    "        {'bbox': (205, 95, 315, 235), 'class_id': 2, 'confidence': 0.82},   # auto 2 (TP)\n",
    "        {'bbox': (355, 115, 475, 275), 'class_id': 5, 'confidence': 0.90},  # autobus (TP)\n",
    "        {'bbox': (35, 205, 85, 345), 'class_id': 0, 'confidence': 0.88},    # persona (TP)\n",
    "        {'bbox': (650, 80, 750, 200), 'class_id': 2, 'confidence': 0.71},   # auto (FP - reflejo en vidrio)\n",
    "        {'bbox': (100, 50, 150, 80), 'class_id': 0, 'confidence': 0.68},    # persona (FP - sombra)\n",
    "        {'bbox': (300, 300, 400, 400), 'class_id': 1, 'confidence': 0.63}   # bicicleta (FP - objeto parcial)\n",
    "    ]\n",
    "    # Nota: auto 3 en (500, 120, 600, 270) no fue detectado (FN)\n",
    "    \n",
    "    metrics_calc.evaluate_detections(predictions_frame3, ground_truth_frame3, iou_threshold=0.5)\n",
    "    \n",
    "    # Calcular y mostrar métricas finales\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RESULTADOS DE EVALUACIÓN COMPLETA (3 frames)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    metrics_calc.print_summary()\n",
    "    \n",
    "    # Análisis detallado de IoU\n",
    "    final_metrics = metrics_calc.get_metrics()\n",
    "    if final_metrics['num_iou_samples'] > 0:\n",
    "        print(f\"\\nANÁLISIS DE IoU:\")\n",
    "        print(f\"   Muestras analizadas: {final_metrics['num_iou_samples']}\")\n",
    "        print(f\"   IoU mínimo: {min(metrics_calc.total_iou):.3f}\")\n",
    "        print(f\"   IoU máximo: {max(metrics_calc.total_iou):.3f}\")\n",
    "        print(f\"   Desviación estándar: {np.std(metrics_calc.total_iou):.3f}\")\n",
    "    \n",
    "    return metrics_calc\n",
    "\n",
    "# Ejecutar simulación\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando evaluación de métricas con datos simulados...\")\n",
    "    print(\"Objetivo: Demostrar precisión del sistema en escenarios reales\\n\")\n",
    "    \n",
    "    # Ejecutar evaluación\n",
    "    evaluator = simulate_traffic_evaluation()\n",
    "    \n",
    "    print(\"\\nEvaluación completada. Las métricas muestran el rendimiento del modelo YOLOv8 en:\")\n",
    "    print(\"   - Detección precisa de objetos de tráfico\")\n",
    "    print(\"   - Manejo de falsos positivos comunes\") \n",
    "    print(\"   - Robustez ante condiciones variables de iluminación\")\n",
    "    print(\"   - Precision balanceada entre recall y especificidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6465c0e",
   "metadata": {},
   "source": [
    "## 8.7. Matriz de Confusión y Métricas Avanzadas\n",
    "\n",
    "La matriz de confusión es una herramienta fundamental para evaluar el rendimiento de clasificación. En nuestro proyecto, se utiliza para analizar la precisión por clase de objeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7beb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de Matriz de Confusión y Visualización\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class ConfusionMatrixAnalyzer:\n",
    "    \"\"\"\n",
    "    Analizador de matriz de confusión para detección multiclase\n",
    "    Especializado en análisis de tráfico con clases COCO relevantes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Mapeo de clases COCO relevantes para tráfico\n",
    "        self.class_names = {\n",
    "            0: 'Persona',\n",
    "            1: 'Bicicleta', \n",
    "            2: 'Auto',\n",
    "            3: 'Motocicleta',\n",
    "            5: 'Autobus',\n",
    "            7: 'Camion'\n",
    "        }\n",
    "        \n",
    "        self.predictions = []\n",
    "        self.ground_truth = []\n",
    "        \n",
    "    def add_predictions(self, pred_classes, true_classes):\n",
    "        \"\"\"\n",
    "        Añade predicciones y clases verdaderas para análisis posterior\n",
    "        \n",
    "        Args:\n",
    "            pred_classes: Lista de clases predichas\n",
    "            true_classes: Lista de clases verdaderas\n",
    "        \"\"\"\n",
    "        self.predictions.extend(pred_classes)\n",
    "        self.ground_truth.extend(true_classes)\n",
    "    \n",
    "    def calculate_confusion_matrix(self):\n",
    "        \"\"\"\n",
    "        Calcula matriz de confusión basada en predicciones acumuladas\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Matriz de confusión normalizada\n",
    "        \"\"\"\n",
    "        if not self.predictions or not self.ground_truth:\n",
    "            print(\"No hay datos suficientes para calcular matriz de confusión\")\n",
    "            return None\n",
    "            \n",
    "        # Obtener clases únicas presentes en los datos\n",
    "        unique_classes = sorted(list(set(self.predictions + self.ground_truth)))\n",
    "        \n",
    "        # Crear matriz de confusión\n",
    "        cm = confusion_matrix(self.ground_truth, self.predictions, labels=unique_classes)\n",
    "        \n",
    "        return cm, unique_classes\n",
    "    \n",
    "    def plot_confusion_matrix(self, normalize=True, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Visualiza matriz de confusión con heatmap\n",
    "        \n",
    "        Args:\n",
    "            normalize: Si normalizar la matriz (porcentajes vs conteos)\n",
    "            figsize: Tamaño de figura para plot\n",
    "        \"\"\"\n",
    "        cm, class_labels = self.calculate_confusion_matrix()\n",
    "        if cm is None:\n",
    "            return\n",
    "            \n",
    "        # Normalizar si se solicita\n",
    "        if normalize:\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            cm_to_plot = cm_normalized\n",
    "            fmt = '.2f'\n",
    "            title = 'Matriz de Confusión Normalizada'\n",
    "        else:\n",
    "            cm_to_plot = cm\n",
    "            fmt = 'd'\n",
    "            title = 'Matriz de Confusión (Conteos)'\n",
    "        \n",
    "        # Crear figura\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Crear nombres de clases para labels\n",
    "        class_names_for_plot = [self.class_names.get(cls, f'Clase {cls}') for cls in class_labels]\n",
    "        \n",
    "        # Crear heatmap\n",
    "        sns.heatmap(cm_to_plot, \n",
    "                   annot=True, \n",
    "                   fmt=fmt, \n",
    "                   cmap='Blues',\n",
    "                   xticklabels=class_names_for_plot,\n",
    "                   yticklabels=class_names_for_plot,\n",
    "                   cbar_kws={'label': 'Proporción' if normalize else 'Conteos'})\n",
    "        \n",
    "        plt.title(title, fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Predicción', fontsize=12)\n",
    "        plt.ylabel('Clase Real', fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Mostrar estadísticas adicionales\n",
    "        self._print_matrix_stats(cm, class_labels, normalize)\n",
    "    \n",
    "    def _print_matrix_stats(self, cm, class_labels, normalized):\n",
    "        \"\"\"Imprime estadísticas detalladas de la matriz de confusión\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ESTADÍSTICAS DE MATRIZ DE CONFUSIÓN\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Accuracy total\n",
    "        total_correct = np.trace(cm)\n",
    "        total_samples = np.sum(cm)\n",
    "        overall_accuracy = total_correct / total_samples\n",
    "        print(f\"Precisión Global: {overall_accuracy:.3f} ({overall_accuracy*100:.1f}%)\")\n",
    "        print(f\"Total de muestras: {total_samples}\")\n",
    "        print(f\"Clasificaciones correctas: {total_correct}\")\n",
    "        \n",
    "        print(f\"\\nMÉTRICAS POR CLASE:\")\n",
    "        \n",
    "        for i, class_id in enumerate(class_labels):\n",
    "            class_name = self.class_names.get(class_id, f'Clase {class_id}')\n",
    "            \n",
    "            # True Positives, False Positives, False Negatives\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp  # suma columna - diagonal\n",
    "            fn = np.sum(cm[i, :]) - tp  # suma fila - diagonal\n",
    "            \n",
    "            # Métricas\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            print(f\"\\n   {class_name} (ID: {class_id}):\")\n",
    "            print(f\"      TP: {tp:3d} | FP: {fp:3d} | FN: {fn:3d}\")\n",
    "            print(f\"      Precision: {precision:.3f}\")\n",
    "            print(f\"      Recall:    {recall:.3f}\")\n",
    "            print(f\"      F1-Score:  {f1:.3f}\")\n",
    "        \n",
    "        # Errores más comunes\n",
    "        print(f\"\\nANÁLISIS DE ERRORES COMUNES:\")\n",
    "        self._analyze_common_errors(cm, class_labels)\n",
    "        \n",
    "    def _analyze_common_errors(self, cm, class_labels):\n",
    "        \"\"\"Identifica los errores de clasificación más frecuentes\"\"\"\n",
    "        \n",
    "        errors = []\n",
    "        \n",
    "        for i in range(len(class_labels)):\n",
    "            for j in range(len(class_labels)):\n",
    "                if i != j and cm[i][j] > 0:  # Error de clasificación\n",
    "                    true_class = self.class_names.get(class_labels[i], f'Clase {class_labels[i]}')\n",
    "                    pred_class = self.class_names.get(class_labels[j], f'Clase {class_labels[j]}')\n",
    "                    count = cm[i][j]\n",
    "                    errors.append((count, true_class, pred_class))\n",
    "        \n",
    "        # Ordenar errores por frecuencia\n",
    "        errors.sort(reverse=True, key=lambda x: x[0])\n",
    "        \n",
    "        print(\"   Top 5 confusiones más frecuentes:\")\n",
    "        for i, (count, true_cls, pred_cls) in enumerate(errors[:5]):\n",
    "            print(f\"      {i+1}. {true_cls} → {pred_cls}: {count} casos\")\n",
    "        \n",
    "        if not errors:\n",
    "            print(\"   No se detectaron errores de clasificación!\")\n",
    "\n",
    "\n",
    "# Ejemplo de uso con datos simulados\n",
    "\n",
    "def demo_confusion_matrix():\n",
    "    \"\"\"\n",
    "    Demostración de análisis de matriz de confusión con datos de tráfico\n",
    "    \"\"\"\n",
    "    print(\"DEMO: Análisis de Matriz de Confusión para Detección de Tráfico\")\n",
    "    print(\"=\"*65)\n",
    "    \n",
    "    # Crear analizador\n",
    "    cm_analyzer = ConfusionMatrixAnalyzer()\n",
    "    \n",
    "    # Simular datos de clasificación (múltiples frames de video)\n",
    "    # Formato: [clase_predicha, clase_real] para cada detección\n",
    "    \n",
    "    # Simulación realista basada en rendimiento típico de YOLOv8\n",
    "    np.random.seed(42)  # Para reproducibilidad\n",
    "    \n",
    "    # Generar datos simulados\n",
    "    detections_data = [\n",
    "        # Personas: alta precisión, algunas confusiones con objetos estáticos\n",
    "        ([0] * 95 + [2] * 3 + [1] * 2, [0] * 100),  # 95% precision en personas\n",
    "        \n",
    "        # Autos: muy alta precisión, clase más robusta\n",
    "        ([2] * 98 + [5] * 1 + [7] * 1, [2] * 100),  # 98% precision en autos\n",
    "        \n",
    "        # Bicicletas: precision moderada, confusión con motocicletas\n",
    "        ([1] * 85 + [3] * 10 + [0] * 5, [1] * 100),  # 85% precision en bicicletas\n",
    "        \n",
    "        # Autobuses: buena precisión, ocasional confusión con camiones\n",
    "        ([5] * 92 + [7] * 6 + [2] * 2, [5] * 100),  # 92% precision en autobuses\n",
    "        \n",
    "        # Camiones: precision alta, distingue bien de otros vehículos\n",
    "        ([7] * 94 + [5] * 4 + [2] * 2, [7] * 100),  # 94% precision en camiones\n",
    "    ]\n",
    "    \n",
    "    # Agregar datos al analizador\n",
    "    for pred_list, true_list in detections_data:\n",
    "        cm_analyzer.add_predictions(pred_list, true_list)\n",
    "    \n",
    "    print(f\"Total de detecciones simuladas: {len(cm_analyzer.predictions)}\")\n",
    "    print(\"Generando matriz de confusión...\\n\")\n",
    "    \n",
    "    # Generar y mostrar matriz de confusión\n",
    "    cm_analyzer.plot_confusion_matrix(normalize=True, figsize=(12, 10))\n",
    "    \n",
    "    return cm_analyzer\n",
    "\n",
    "# Ejecutar demostración\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Iniciando análisis de matriz de confusión...\")\n",
    "    analyzer = demo_confusion_matrix()\n",
    "    print(\"\\nAnálisis completado. La matriz muestra:\")\n",
    "    print(\"   - Precisión por clase de objeto\")\n",
    "    print(\"   - Patrones de confusión comunes\")\n",
    "    print(\"   - Áreas de mejora del modelo\")\n",
    "    print(\"   - Rendimiento general del sistema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb46cae",
   "metadata": {},
   "source": [
    "## 8.8. Interpretación de Resultados y Optimización del Sistema\n",
    "\n",
    "### 8.8.1. Criterios de Evaluación para Sistemas de Tráfico\n",
    "\n",
    "El análisis de las métricas implementadas nos permite establecer criterios de calidad específicos para sistemas de análisis de tráfico:\n",
    "\n",
    "**Métricas Target para Aplicaciones de Tráfico:**\n",
    "- **Precision ≥ 0.85**: Minimizar falsos positivos para evitar alertas erróneas\n",
    "- **Recall ≥ 0.80**: Asegurar detección de la mayoría de objetos relevantes\n",
    "- **IoU ≥ 0.50**: Localización precisa para análisis de flujo y conteo\n",
    "- **F1-Score ≥ 0.82**: Balance entre precision y recall\n",
    "\n",
    "### 8.8.2. Análisis por Clase de Objeto\n",
    "\n",
    "**Clases de Alta Prioridad:**\n",
    "- **Personas**: Crítico para seguridad peatonal (Target: Recall ≥ 0.90)\n",
    "- **Vehículos**: Esencial para análisis de flujo vehicular (Target: Precision ≥ 0.88)\n",
    "\n",
    "**Optimizaciones Específicas:**\n",
    "- **Bicicletas**: Ajuste de umbral de confianza para reducir confusión con motocicletas\n",
    "- **Vehículos Pesados**: Refinamiento de anchors para mejor detección de objetos grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema Integrado de Evaluación y Optimización\n",
    "\n",
    "class TrafficSystemEvaluator:\n",
    "    \"\"\"\n",
    "    Sistema completo de evaluación para análisis de tráfico\n",
    "    Integra todas las métricas desarrolladas para optimización continua\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_precision=0.85, target_recall=0.80, target_iou=0.50):\n",
    "        self.metrics_calc = MetricsCalculator()\n",
    "        self.confusion_analyzer = ConfusionMatrixAnalyzer()\n",
    "        \n",
    "        # Targets de rendimiento\n",
    "        self.targets = {\n",
    "            'precision': target_precision,\n",
    "            'recall': target_recall, \n",
    "            'iou': target_iou,\n",
    "            'f1_score': 2 * (target_precision * target_recall) / (target_precision + target_recall)\n",
    "        }\n",
    "        \n",
    "        # Contadores para optimización\n",
    "        self.evaluation_history = []\n",
    "        \n",
    "    def evaluate_system_performance(self, predictions_batch, ground_truth_batch, \n",
    "                                  confidence_threshold=0.5, iou_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Evaluación completa del sistema en un lote de datos\n",
    "        \n",
    "        Args:\n",
    "            predictions_batch: Lista de predicciones por frame\n",
    "            ground_truth_batch: Lista de ground truth por frame\n",
    "            confidence_threshold: Umbral de confianza para filtrar predicciones\n",
    "            iou_threshold: Umbral IoU para considerar match válido\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"EVALUANDO RENDIMIENTO DEL SISTEMA...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Reiniciar métricas\n",
    "        self.metrics_calc.reset()\n",
    "        self.confusion_analyzer = ConfusionMatrixAnalyzer()\n",
    "        \n",
    "        processed_frames = 0\n",
    "        total_detections = 0\n",
    "        \n",
    "        for frame_idx, (predictions, ground_truth) in enumerate(zip(predictions_batch, ground_truth_batch)):\n",
    "            # Filtrar predicciones por confianza\n",
    "            filtered_predictions = [\n",
    "                pred for pred in predictions \n",
    "                if pred.get('confidence', 0) >= confidence_threshold\n",
    "            ]\n",
    "            \n",
    "            # Evaluar frame\n",
    "            self.metrics_calc.evaluate_detections(filtered_predictions, ground_truth, iou_threshold)\n",
    "            \n",
    "            # Agregar datos para matriz de confusión\n",
    "            pred_classes = [pred['class_id'] for pred in filtered_predictions]\n",
    "            true_classes = [gt['class_id'] for gt in ground_truth]\n",
    "            \n",
    "            if pred_classes and true_classes:\n",
    "                self.confusion_analyzer.add_predictions(pred_classes, true_classes)\n",
    "            \n",
    "            processed_frames += 1\n",
    "            total_detections += len(filtered_predictions)\n",
    "        \n",
    "        # Obtener métricas finales\n",
    "        final_metrics = self.metrics_calc.get_metrics()\n",
    "        \n",
    "        # Guardar en historial\n",
    "        evaluation_record = {\n",
    "            'timestamp': processed_frames,\n",
    "            'metrics': final_metrics,\n",
    "            'confidence_threshold': confidence_threshold,\n",
    "            'iou_threshold': iou_threshold,\n",
    "            'total_detections': total_detections\n",
    "        }\n",
    "        self.evaluation_history.append(evaluation_record)\n",
    "        \n",
    "        # Análisis de rendimiento\n",
    "        self._analyze_performance(final_metrics)\n",
    "        \n",
    "        return final_metrics\n",
    "    \n",
    "    def _analyze_performance(self, metrics):\n",
    "        \"\"\"Analiza rendimiento contra targets establecidos\"\"\"\n",
    "        \n",
    "        print(f\"\\nANÁLISIS DE RENDIMIENTO vs TARGETS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Comparar con targets\n",
    "        performance_status = {}\n",
    "        \n",
    "        for metric_name, target_value in self.targets.items():\n",
    "            actual_value = metrics.get(metric_name, 0.0)\n",
    "            meets_target = actual_value >= target_value\n",
    "            performance_status[metric_name] = meets_target\n",
    "            \n",
    "            status_icon = \"[OK]\" if meets_target else \"[FALTA]\"\n",
    "            print(f\"{status_icon} {metric_name.capitalize()}: {actual_value:.3f} (target: {target_value:.3f})\")\n",
    "        \n",
    "        # Evaluación general\n",
    "        overall_performance = sum(performance_status.values()) / len(performance_status)\n",
    "        print(f\"\\nRENDIMIENTO GENERAL: {overall_performance*100:.1f}%\")\n",
    "        \n",
    "        if overall_performance >= 0.75:\n",
    "            print(\"Sistema operando dentro de parámetros óptimos\")\n",
    "        elif overall_performance >= 0.50:\n",
    "            print(\"Sistema requiere ajustes menores\")\n",
    "        else:\n",
    "            print(\"Sistema requiere optimización significativa\")\n",
    "        \n",
    "        # Recomendaciones específicas\n",
    "        self._provide_optimization_recommendations(metrics, performance_status)\n",
    "    \n",
    "    def _provide_optimization_recommendations(self, metrics, performance_status):\n",
    "        \"\"\"Proporciona recomendaciones específicas de optimización\"\"\"\n",
    "        \n",
    "        print(f\"\\nRECOMENDACIONES DE OPTIMIZACIÓN:\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # Análisis de precision\n",
    "        if not performance_status['precision']:\n",
    "            recommendations.append(\n",
    "                \"Incrementar umbral de confianza para reducir falsos positivos\"\n",
    "            )\n",
    "            recommendations.append(\n",
    "                \"Revisar classes con mayor tasa de falsos positivos\"\n",
    "            )\n",
    "        \n",
    "        # Análisis de recall\n",
    "        if not performance_status['recall']:\n",
    "            recommendations.append(\n",
    "                \"Reducir umbral de confianza para capturar más objetos\"\n",
    "            )\n",
    "            recommendations.append(\n",
    "                \"Considerar data augmentation para clases con bajo recall\"\n",
    "            )\n",
    "        \n",
    "        # Análisis de IoU\n",
    "        if not performance_status['iou']:\n",
    "            recommendations.append(\n",
    "                \"Ajustar arquitectura para mejor localización de objetos\"\n",
    "            )\n",
    "            recommendations.append(\n",
    "                \"Revisar anchor boxes para mejor ajuste de bounding boxes\"\n",
    "            )\n",
    "        \n",
    "        # Recomendaciones por clase\n",
    "        class_metrics = metrics.get('class_metrics', {})\n",
    "        for class_id, class_stats in class_metrics.items():\n",
    "            class_name = {0:'Persona', 1:'Bicicleta', 2:'Auto', 3:'Motocicleta', \n",
    "                         5:'Autobus', 7:'Camion'}.get(class_id, f'Clase {class_id}')\n",
    "            \n",
    "            if class_stats['precision'] < 0.80:\n",
    "                recommendations.append(\n",
    "                    f\"Optimizar detección de {class_name} - precision baja ({class_stats['precision']:.2f})\"\n",
    "                )\n",
    "            \n",
    "            if class_stats['recall'] < 0.75:\n",
    "                recommendations.append(\n",
    "                    f\"Mejorar recall para {class_name} - muchos objetos no detectados ({class_stats['recall']:.2f})\"\n",
    "                )\n",
    "        \n",
    "        # Mostrar recomendaciones\n",
    "        if recommendations:\n",
    "            for i, rec in enumerate(recommendations[:5], 1):  # Top 5\n",
    "                print(f\"   {i}. {rec}\")\n",
    "        else:\n",
    "            print(\"   Sistema optimamente configurado - no se requieren ajustes\")\n",
    "    \n",
    "    def generate_performance_report(self):\n",
    "        \"\"\"Genera reporte completo de rendimiento\"\"\"\n",
    "        \n",
    "        if not self.evaluation_history:\n",
    "            print(\"No hay datos de evaluación disponibles\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"REPORTE COMPLETO DE RENDIMIENTO DEL SISTEMA\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Último resultado\n",
    "        latest_eval = self.evaluation_history[-1]\n",
    "        latest_metrics = latest_eval['metrics']\n",
    "        \n",
    "        print(f\"Última evaluación:\")\n",
    "        print(f\"   Frames procesados: {latest_eval['timestamp']}\")\n",
    "        print(f\"   Detecciones totales: {latest_eval['total_detections']}\")\n",
    "        print(f\"   Umbral confianza: {latest_eval['confidence_threshold']}\")\n",
    "        print(f\"   Umbral IoU: {latest_eval['iou_threshold']}\")\n",
    "        \n",
    "        # Métricas clave\n",
    "        print(f\"\\nMÉTRICAS PRINCIPALES:\")\n",
    "        self.metrics_calc.print_summary()\n",
    "        \n",
    "        # Matriz de confusión\n",
    "        print(f\"\\nANÁLISIS DE MATRIZ DE CONFUSIÓN:\")\n",
    "        self.confusion_analyzer.plot_confusion_matrix(normalize=True, figsize=(10, 8))\n",
    "        \n",
    "        return latest_metrics\n",
    "\n",
    "# Ejemplo de uso integral del sistema\n",
    "def comprehensive_system_demo():\n",
    "    \"\"\"\n",
    "    Demostración completa del sistema de evaluación integrado\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"DEMO COMPLETA: Sistema Integrado de Evaluación de Tráfico\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Crear evaluador del sistema\n",
    "    evaluator = TrafficSystemEvaluator(\n",
    "        target_precision=0.85,\n",
    "        target_recall=0.80, \n",
    "        target_iou=0.50\n",
    "    )\n",
    "    \n",
    "    # Simular datos de múltiples frames (resultado de procesamiento de video)\n",
    "    print(\"Simulando procesamiento de 5 frames de video de tráfico...\\n\")\n",
    "    \n",
    "    # Datos simulados realistas\n",
    "    predictions_batch = [\n",
    "        # Frame 1: Intersección urbana\n",
    "        [\n",
    "            {'bbox': (100, 150, 200, 300), 'class_id': 0, 'confidence': 0.92},\n",
    "            {'bbox': (250, 100, 400, 250), 'class_id': 2, 'confidence': 0.88},\n",
    "            {'bbox': (450, 120, 580, 280), 'class_id': 2, 'confidence': 0.85},\n",
    "            {'bbox': (600, 80, 750, 200), 'class_id': 5, 'confidence': 0.79}\n",
    "        ],\n",
    "        # Frame 2: Calle residencial  \n",
    "        [\n",
    "            {'bbox': (155, 205, 295, 395), 'class_id': 0, 'confidence': 0.94},\n",
    "            {'bbox': (405, 185, 545, 315), 'class_id': 1, 'confidence': 0.89}\n",
    "        ],\n",
    "        # Frame 3: Avenida principal\n",
    "        [\n",
    "            {'bbox': (85, 105, 175, 245), 'class_id': 2, 'confidence': 0.86},\n",
    "            {'bbox': (205, 95, 315, 235), 'class_id': 2, 'confidence': 0.82},\n",
    "            {'bbox': (355, 115, 475, 275), 'class_id': 5, 'confidence': 0.90},\n",
    "            {'bbox': (500, 125, 625, 285), 'class_id': 7, 'confidence': 0.87}\n",
    "        ],\n",
    "        # Frame 4: Zona peatonal\n",
    "        [\n",
    "            {'bbox': (120, 180, 220, 350), 'class_id': 0, 'confidence': 0.91},\n",
    "            {'bbox': (280, 160, 380, 340), 'class_id': 0, 'confidence': 0.89},\n",
    "            {'bbox': (450, 200, 550, 380), 'class_id': 1, 'confidence': 0.83}\n",
    "        ],\n",
    "        # Frame 5: Estacionamiento\n",
    "        [\n",
    "            {'bbox': (100, 100, 250, 280), 'class_id': 2, 'confidence': 0.93},\n",
    "            {'bbox': (300, 90, 450, 270), 'class_id': 2, 'confidence': 0.91},\n",
    "            {'bbox': (500, 110, 650, 290), 'class_id': 2, 'confidence': 0.88}\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    ground_truth_batch = [\n",
    "        # GT Frame 1\n",
    "        [\n",
    "            {'bbox': (105, 155, 195, 295), 'class_id': 0},\n",
    "            {'bbox': (245, 95, 395, 245), 'class_id': 2},\n",
    "            {'bbox': (455, 125, 575, 275), 'class_id': 2},\n",
    "            {'bbox': (605, 85, 745, 195), 'class_id': 5}\n",
    "        ],\n",
    "        # GT Frame 2\n",
    "        [\n",
    "            {'bbox': (150, 200, 290, 390), 'class_id': 0},\n",
    "            {'bbox': (400, 180, 540, 310), 'class_id': 1}\n",
    "        ],\n",
    "        # GT Frame 3\n",
    "        [\n",
    "            {'bbox': (80, 100, 170, 240), 'class_id': 2},\n",
    "            {'bbox': (200, 90, 310, 230), 'class_id': 2},\n",
    "            {'bbox': (350, 110, 470, 270), 'class_id': 5},\n",
    "            {'bbox': (495, 120, 620, 280), 'class_id': 7}\n",
    "        ],\n",
    "        # GT Frame 4\n",
    "        [\n",
    "            {'bbox': (115, 175, 215, 345), 'class_id': 0},\n",
    "            {'bbox': (275, 155, 375, 335), 'class_id': 0},\n",
    "            {'bbox': (445, 195, 545, 375), 'class_id': 1}\n",
    "        ],\n",
    "        # GT Frame 5\n",
    "        [\n",
    "            {'bbox': (95, 95, 245, 275), 'class_id': 2},\n",
    "            {'bbox': (295, 85, 445, 265), 'class_id': 2},\n",
    "            {'bbox': (495, 105, 645, 285), 'class_id': 2}\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    # Evaluar sistema\n",
    "    final_metrics = evaluator.evaluate_system_performance(\n",
    "        predictions_batch, \n",
    "        ground_truth_batch,\n",
    "        confidence_threshold=0.75,  # Umbral más estricto\n",
    "        iou_threshold=0.5\n",
    "    )\n",
    "    \n",
    "    # Generar reporte completo\n",
    "    evaluator.generate_performance_report()\n",
    "    \n",
    "    print(\"\\nDEMOSTRACIÓN COMPLETADA\")\n",
    "    print(\"El sistema integrado de evaluación proporciona:\")\n",
    "    print(\"   - Métricas precisas de rendimiento\")\n",
    "    print(\"   - Recomendaciones específicas de optimización\")\n",
    "    print(\"   - Análisis detallado por clase de objeto\")\n",
    "    print(\"   - Monitoreo continuo de calidad del sistema\")\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "# Ejecutar demostración completa\n",
    "if __name__ == \"__main__\":\n",
    "    demo_evaluator = comprehensive_system_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f6a744",
   "metadata": {},
   "source": [
    "## 8.9. Conclusiones sobre el Sistema de Métricas\n",
    "\n",
    "### 8.9.1. Resumen de Implementación\n",
    "\n",
    "El sistema de métricas desarrollado para este proyecto proporciona una evaluación completa y robusta del rendimiento del modelo YOLOv8 en aplicaciones de análisis de tráfico. Las implementaciones incluyen:\n",
    "\n",
    "- **MetricsCalculator**: Cálculo preciso de IoU, Precision, Recall y F1-Score\n",
    "- **ConfusionMatrixAnalyzer**: Análisis detallado de confusiones entre clases\n",
    "- **TrafficSystemEvaluator**: Sistema integrado con recomendaciones de optimización\n",
    "\n",
    "### 8.9.2. Ventajas del Enfoque Implementado\n",
    "\n",
    "1. **Estándares COCO**: Compatibilidad con métricas estándar de la industria\n",
    "2. **Evaluación por Clase**: Análisis específico para cada tipo de objeto de tráfico\n",
    "3. **Retroalimentación Automatizada**: Recomendaciones automáticas de optimización\n",
    "4. **Escalabilidad**: Diseño modular para fácil extensión y mantenimiento\n",
    "\n",
    "### 8.9.3. Aplicaciones Prácticas\n",
    "\n",
    "**Optimización Continua**: El sistema permite ajustar umbralres de confianza y IoU en tiempo real basado en métricas observadas.\n",
    "\n",
    "**Control de Calidad**: Monitoreo automático de degradación del rendimiento del modelo en producción.\n",
    "\n",
    "**Análisis Temporal**: Tracking de métricas a lo largo del tiempo para detectar patrones de rendimiento.\n",
    "\n",
    "### 8.9.4. Impacto en el Proyecto\n",
    "\n",
    "La implementación de estas métricas asegura que el sistema de seguimiento de personas y análisis de tráfico mantenga altos estándares de precisión y confiabilidad, fundamentales para aplicaciones de seguridad vial y gestión de tráfico urbano.\n",
    "\n",
    "---\n",
    "\n",
    "**Nota**: Todas las implementaciones están optimizadas para procesamiento en tiempo real y compatibilidad con Google Colab, permitiendo evaluación inmediata del rendimiento del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe651a2",
   "metadata": {},
   "source": [
    "# 9. Resultados y Conclusiones\n",
    "\n",
    "## Resultados Obtenidos\n",
    "\n",
    "### Logros del Proyecto\n",
    "\n",
    "1. **Detección Precisa**\n",
    "   - Tasa de detección: ~85-95% en condiciones óptimas\n",
    "   - Umbrales ajustados por clase para balance precisión/recall\n",
    "   - Filtrado por área para eliminar falsos positivos\n",
    "\n",
    "2. **Tracking Funcional**\n",
    "   - IDs únicos persistentes entre frames\n",
    "   - Trayectorias visuales para análisis de movimiento\n",
    "   - Sistema de \"desaparición\" para objetos fuera de vista\n",
    "\n",
    "3. **Casos de Uso Prácticos**\n",
    "   - Control de aforo operativo\n",
    "   - Análisis de flujo vehicular funcionando\n",
    "   - Interfaz intuitiva con indicadores visuales\n",
    "\n",
    "### Métricas de Rendimiento\n",
    "\n",
    "| Métrica | Valor |\n",
    "|---------|-------|\n",
    "| FPS promedio (YOLOv8n) | 30-60 FPS |\n",
    "| Tiempo de inferencia | ~16-33 ms/imagen |\n",
    "| Precisión personas | ~88% |\n",
    "| Precisión vehículos | ~82% |\n",
    "| Tamaño modelo | 6 MB |\n",
    "\n",
    "---\n",
    "\n",
    "## Ventajas del Sistema\n",
    "\n",
    "### Técnicas\n",
    "- **Pre-entrenado**: No requiere entrenamiento adicional\n",
    "- **Ligero**: YOLOv8n corre en CPU sin problemas\n",
    "- **Versátil**: Detecta 80 clases de COCO\n",
    "- **Modular**: Código organizado en clases reutilizables\n",
    "\n",
    "### Prácticas\n",
    "- **Implementación rápida**: Minutos, no días\n",
    "- **Bajo costo**: No requiere hardware especializado\n",
    "- **Escalable**: Fácil adaptar a nuevos casos de uso\n",
    "- **Interpretable**: Visualizaciones claras\n",
    "\n",
    "---\n",
    "\n",
    "## Limitaciones y Mejoras Futuras\n",
    "\n",
    "### Limitaciones Actuales\n",
    "\n",
    "1. **Oclusión**: Dificultad con objetos parcialmente ocultos\n",
    "2. **Distancia**: Menor precisión con objetos muy lejanos\n",
    "3.  **Condiciones**: Afectado por poca luz o clima extremo\n",
    "4. **Imágenes estáticas**: No aprovecha información temporal del video\n",
    "\n",
    "### Mejoras Propuestas\n",
    "\n",
    "1. **Tracking avanzado**: Implementar DeepSORT o ByteTrack\n",
    "2. **Video en tiempo real**: Soporte para streams de cámaras\n",
    "3. **Base de datos**: Almacenar históricos para análisis\n",
    "4. **Alertas automáticas**: Notificaciones por email/SMS\n",
    "5. **Dashboard web**: Interfaz web con Flask/Streamlit\n",
    "6. **Modelo personalizado**: Fine-tuning en dataset específico\n",
    "\n",
    "---\n",
    "\n",
    "## Aplicaciones del Mundo Real\n",
    "\n",
    "### Comercio\n",
    "- Control de aforo en tiendas\n",
    "- Análisis de zonas calientes (heatmaps)\n",
    "- Medición de tiempos de estancia\n",
    "- Optimización de layout\n",
    "\n",
    "### Transporte\n",
    "- Monitoreo de tráfico urbano\n",
    "- Detección de congestión\n",
    "- Estadísticas de flujo vehicular\n",
    "- Planificación de semáforos inteligentes\n",
    "\n",
    "### Seguridad\n",
    "- Control de acceso\n",
    "- Zonas restringidas\n",
    "- Conteo de ocupantes\n",
    "- Detección de aglomeraciones\n",
    "\n",
    "### Eventos\n",
    "- Gestión de capacidad\n",
    "- Control de entradas/salidas\n",
    "- Seguridad en eventos masivos\n",
    "- Análisis post-evento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56e473",
   "metadata": {},
   "source": [
    "# Conclusiones Finales\n",
    "\n",
    "## Resumen del Proyecto\n",
    "\n",
    "Este proyecto demuestra cómo **YOLOv8** y el **dataset COCO** pueden combinarse para crear soluciones prácticas de visión por computadora sin necesidad de entrenar modelos desde cero.\n",
    "\n",
    "### Logros Clave:\n",
    "\n",
    "1. **Sistema funcional** de detección y tracking\n",
    "2. **Dos casos de uso implementados**: aforo y flujo vehicular\n",
    "3. **Código modular y reutilizable**\n",
    "4. **Interfaz intuitiva** con indicadores visuales\n",
    "5. **Documentación completa** (este notebook)\n",
    "\n",
    "### Aprendizajes:\n",
    "\n",
    "- **COCO dataset**: Estándar de la industria para visión por computadora\n",
    "- **YOLOv8**: Balance óptimo entre velocidad y precisión\n",
    "- **Transfer Learning**: Aprovechar modelos pre-entrenados\n",
    "- **Tracking**: Mantener identidad de objetos a través del tiempo\n",
    "- **Aplicaciones reales**: Traducir tecnología a soluciones prácticas\n",
    "\n",
    "---\n",
    "\n",
    "## Referencias y Recursos\n",
    "\n",
    "### Documentación Oficial\n",
    "\n",
    "- **YOLOv8**: https://docs.ultralytics.com/\n",
    "- **COCO Dataset**: https://cocodataset.org/\n",
    "- **OpenCV**: https://docs.opencv.org/\n",
    "\n",
    "### Papers Relevantes\n",
    "\n",
    "- **YOLO**: Redmon et al. \"You Only Look Once: Unified, Real-Time Object Detection\" (2016)\n",
    "- **YOLOv8**: Ultralytics YOLOv8 Documentation\n",
    "- **COCO**: Lin et al. \"Microsoft COCO: Common Objects in Context\" (2014)\n",
    "\n",
    "### Recursos Adicionales\n",
    "\n",
    "- **Ultralytics GitHub**: https://github.com/ultralytics/ultralytics\n",
    "- **COCO API**: https://github.com/cocodataset/cocoapi\n",
    "- **Deep Learning para Visión por Computadora**: Stanford CS231n\n",
    "\n",
    "---\n",
    "\n",
    "## Créditos\n",
    "\n",
    "**Miranda Alison, Morán David y VIvanco Gabriel**  \n",
    "Proyecto desarrollado para la materia de Aplicaciones Basadas en el Conocimiento  \n",
    "Universidad: Universidad de las Fuerzas Armadas - EPE\n",
    "Fecha: Febrero 2026\n",
    "\n",
    "**Tecnologías utilizadas:**\n",
    "- Python 3.13+\n",
    "- YOLOv8 (Ultralytics)\n",
    "- OpenCV\n",
    "- COCO Dataset\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
